{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_csv(\"HASYv2/hasy-data-labels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "include = np.arange(70, 80, 1)\n",
    "\n",
    "y = labels.loc[labels['symbol_id'].isin(include)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1020, 4)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check numbers of examples\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1020, 1024)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.misc import imread\n",
    "\n",
    "# Read the specified images as flat vectors\n",
    "samples = []\n",
    "for filename in y[\"path\"]:\n",
    "    img = imread(\"HASYv2/\"+filename, mode='L').reshape(-1)\n",
    "    samples.append(img)\n",
    "\n",
    "X = pd.DataFrame.from_records(samples).as_matrix()\n",
    "# Check dims\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(816, 1024) (816,) (204, 1024) (204,)\n"
     ]
    }
   ],
   "source": [
    "# Split into train and test and take only labels from y\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "X, y = shuffle(X, y)\n",
    "\n",
    "X_train = X[:int(X.shape[0] * 0.8), :]\n",
    "y_train = y[\"symbol_id\"].as_matrix()[:int(y.shape[0] * 0.8)]\n",
    "\n",
    "X_test = X[int(X.shape[0] * 0.8):, :]\n",
    "y_test = y[\"symbol_id\"].as_matrix()[int(y.shape[0] * 0.8):]\n",
    "\n",
    "# Confirm shapes\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression()\n",
    "\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.877450980392\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on test set\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(accuracy_score(y_test, lr.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.107843137255\n"
     ]
    }
   ],
   "source": [
    "# Naive classifier\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "def naive_classify(y_train, X_test):\n",
    "    most_common = int(stats.mode(y_train).mode[0])\n",
    "    return np.ones(X_test.shape[0]) * most_common\n",
    "\n",
    "print(accuracy_score(y_test, naive_classify(y_train, X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This time train a random forest classifier on the data. A random forest is a collection of decision trees, which makes it an ensemble of classifiers. Each tree uses a random subset of the features to make it's prediction. Without tuning any parameters, how is the accuracy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.745098039216\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "print(accuracy_score(y_test, rf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The amount of trees to use as a part of the random forest is an example of a hyperparameter, because it is a parameter that is set prior to the learning process. In contrast, a parameter is a value in the model that is learned from the data. Train 20 classifiers, with varying amounts of decision trees starting from 10 up until 200, and plot the test accuracy as a function of the amount of classifiers. Does the accuracy keep increasing? Is more better?\n",
    "\n",
    "Clearly more is not better, but the accuracy is more or less the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f909218bd68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "accs = []\n",
    "trees = np.arange(10, 200, 10)\n",
    "for i in trees:\n",
    "    rf = RandomForestClassifier(n_estimators=i)\n",
    "    rf.fit(X_train, y_train)\n",
    "\n",
    "    acc = accuracy_score(y_test, rf.predict(X_test))\n",
    "    accs.append(acc)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(trees, accs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If we had picked the amount of decision trees by taking the value with the best test accuracy from the last plot, we would have overfit our hyperparameters to the test data. Can you see why it is a mistake to tune hyperparameters of your model by using the test data?\n",
    "\n",
    "Finding the optimal parameters for your test data simply overfits to it, and since we are interested in how well the model generalizes, this is a bad thing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshuffle and resplit the data so that it is divided in 3 parts: training (80%), validation (10%) and test (10%). Repeatedly train a model of your choosing (e.g random forest) on the training data, and evaluate it's performance on the validation set, while tuning the hyperparameters so that the accuracy on the validation set increases. Then, finally evaluate the performance of your model on the test data. What can you say in terms of the generalization of your model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(816, 1024) (816,) (102, 1024) (102,) (102, 1024) (102,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "X, y = shuffle(X, y)\n",
    "\n",
    "train_part = int(X.shape[0] * 0.8)\n",
    "val_part = int(X.shape[0] * 0.1)\n",
    "\n",
    "X_train = X[:train_part, :]\n",
    "y_train = y[\"symbol_id\"].as_matrix()[:train_part]\n",
    "\n",
    "X_val = X[train_part: train_part + val_part, :]\n",
    "y_val = y[\"symbol_id\"].as_matrix()[train_part: train_part + val_part:]\n",
    "\n",
    "X_test = X[train_part + val_part:, :]\n",
    "y_test = y[\"symbol_id\"].as_matrix()[train_part + val_part:]\n",
    "\n",
    "# Confirm shapes\n",
    "print(X_train.shape, y_train.shape, X_val.shape, y_val.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best val acc 600\n"
     ]
    }
   ],
   "source": [
    "sizes = np.arange(100, 1000, 100)\n",
    "val_accs = np.zeros(len(sizes))\n",
    "classifiers = []\n",
    "\n",
    "for idx, size in enumerate(sizes):\n",
    "    rf = RandomForestClassifier(n_estimators=size)\n",
    "    rf.fit(X_train, y_train)\n",
    "\n",
    "    acc = accuracy_score(y_val, rf.predict(X_val))\n",
    "    val_accs[idx] = acc\n",
    "    classifiers.append(rf)\n",
    "\n",
    "print(\"best val acc\", sizes[np.argmax(val_accs)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.872549019608\n"
     ]
    }
   ],
   "source": [
    "# Evaluate best classifier on test set\n",
    "# Accuracy is much better than without tuning\n",
    "\n",
    "best = classifiers[np.argmax(val_accs)]\n",
    "\n",
    "print(accuracy_score(y_test, best.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This process of picking a suitable model, evaluating it's performance and tuning the hyperparameters is very time consuming. A new idea in machine learning is the concept of automating this by using an optimization algorithm to find the best model in the space of models and their hyperparameters. Have a look at TPOT, an automated ML solution that finds a good model and a good set of hyperparameters automatically. Try it on this data, it should outperform simple models like the ones we tried easily. Note that running the algorithm might take a while, depending on the strength of your computer. TPOT uses cross-validation internally, so we don't need our own validation set.\n",
    "\n",
    "TPOT does the tuning for us, trying out different models and different hyperparameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version 0.8.3 of tpot is outdated. Version 0.9.0 was released 3 days ago.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimization Progress:  50%|█████     | 6/12 [00:24<00:46,  7.68s/pipeline]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 1 - Current best internal CV score: 0.8011768383848363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimization Progress:  75%|███████▌  | 9/12 [00:40<00:25,  8.62s/pipeline]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 2 - Current best internal CV score: 0.8011768383848363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 3 - Current best internal CV score: 0.8011768383848363\n",
      "\n",
      "Best pipeline: ExtraTreesClassifier(input_matrix, ExtraTreesClassifier__bootstrap=False, ExtraTreesClassifier__criterion=gini, ExtraTreesClassifier__max_features=0.1, ExtraTreesClassifier__min_samples_leaf=3, ExtraTreesClassifier__min_samples_split=13, ExtraTreesClassifier__n_estimators=100)\n",
      "0.852941176471\n"
     ]
    }
   ],
   "source": [
    "from tpot import TPOTClassifier\n",
    "tpot = TPOTClassifier(generations=3, population_size=3, verbosity=2, max_eval_time_mins=1)\n",
    "tpot.fit(X_train, y_train)\n",
    "print(tpot.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
